{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PART 1: INSTALL REQUIRED LIBRARIES\n",
        "# ==============================================================================\n",
        "print(\"‚è≥ Installing required libraries...\")\n",
        "!pip install gradio groq huggingface_hub -q\n",
        "print(\"‚úÖ Libraries installed.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# PART 2: IMPORTS, API KEY SETUP, AND AUTHENTICATION\n",
        "# ==============================================================================\n",
        "import gradio as gr\n",
        "import os\n",
        "from groq import AsyncGroq, Groq\n",
        "from huggingface_hub import InferenceClient, HfFolder\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"üîë Setting up API keys and authentication...\")\n",
        "\n",
        "# Securely get the Groq API key\n",
        "try:\n",
        "    GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "    os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "    print(\"‚úÖ Groq API Key loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not load Groq API Key. Please add it to Colab Secrets. Error: {e}\")\n",
        "\n",
        "# Securely get the Hugging Face token (only for image generation)\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HUGGING_FACE_API_KEY')\n",
        "    HfFolder.save_token(HF_TOKEN)\n",
        "    print(\"‚úÖ Hugging Face Token loaded and authenticated.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not load Hugging Face Token. Please add it to Colab Secrets. Error: {e}\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# PART 3: INITIALIZE API CLIENTS\n",
        "# ==============================================================================\n",
        "print(\"‚òÅÔ∏è Initializing API clients...\")\n",
        "\n",
        "# 1. Groq Clients (Async for chatbot, Sync for audio transcription)\n",
        "try:\n",
        "    groq_async_client = AsyncGroq()\n",
        "    groq_sync_client = Groq()\n",
        "    print(\"‚úÖ Groq clients initialized (async and sync).\")\n",
        "except Exception as e:\n",
        "    print(f\"üî• Error initializing Groq clients: {e}\")\n",
        "\n",
        "# 2. Hugging Face Inference Client (only for Image Generation)\n",
        "try:\n",
        "    inference_client = InferenceClient(token=HF_TOKEN)\n",
        "    print(\"‚úÖ Hugging Face Inference client initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"üî• Error initializing Hugging Face client: {e}\")\n",
        "\n",
        "# Define the image model\n",
        "IMAGE_MODEL_ID = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# PART 4: DEFINE CORE FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Function for Tab 1: Audio Processing (Using Groq for transcription & translation) ---\n",
        "async def process_audio_and_generate(audio_path, source_language, generate_image_checkbox):\n",
        "    if not audio_path:\n",
        "        gr.Warning(\"No audio file provided. Please upload an audio file.\")\n",
        "        return \"\", \"\", None\n",
        "\n",
        "    transcription, english_text, image_output = \"\", \"\", None\n",
        "    detected_language = \"\"\n",
        "\n",
        "    # 1. Transcribe audio to text (Using Groq Whisper)\n",
        "    try:\n",
        "        print(\"üé§ Calling Groq API for transcription...\")\n",
        "\n",
        "        with open(audio_path, \"rb\") as audio_file:\n",
        "            # Auto-detect language if not specified\n",
        "            if source_language == \"Auto-detect\":\n",
        "                transcription_result = groq_sync_client.audio.transcriptions.create(\n",
        "                    file=(audio_path, audio_file.read()),\n",
        "                    model=\"whisper-large-v3\",\n",
        "                    response_format=\"verbose_json\"\n",
        "                )\n",
        "                detected_language = transcription_result.language\n",
        "                print(f\"üîç Detected language: {detected_language}\")\n",
        "            else:\n",
        "                # Use specified language\n",
        "                lang_code = \"ta\" if source_language == \"Tamil\" else \"en\"\n",
        "                transcription_result = groq_sync_client.audio.transcriptions.create(\n",
        "                    file=(audio_path, audio_file.read()),\n",
        "                    model=\"whisper-large-v3\",\n",
        "                    language=lang_code,\n",
        "                    response_format=\"json\"\n",
        "                )\n",
        "                detected_language = source_language\n",
        "\n",
        "        transcription = transcription_result.text\n",
        "        print(f\"‚úÖ Transcription: {transcription}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        gr.Error(f\"Groq transcription failed! Error: {e}\")\n",
        "        return \"Transcription Failed\", \"\", None\n",
        "\n",
        "    # 2. Translate text to English (Using Groq) - Only if not already in English\n",
        "    try:\n",
        "        # Check if the audio is already in English\n",
        "        if detected_language.lower() in [\"english\", \"en\"]:\n",
        "            english_text = transcription\n",
        "            print(\"‚úÖ Audio is already in English, skipping translation.\")\n",
        "        else:\n",
        "            print(\"üåê Calling Groq API for translation...\")\n",
        "            translation_prompt = f\"Translate the following text to English. Provide only the English translation and nothing else. Text: '{transcription}'\"\n",
        "\n",
        "            chat_completion = await groq_async_client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful translation assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": translation_prompt}\n",
        "                ],\n",
        "                model=\"moonshotai/kimi-k2-instruct\",\n",
        "            )\n",
        "            english_text = chat_completion.choices[0].message.content.strip()\n",
        "            print(f\"‚úÖ Translation: {english_text}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        gr.Error(f\"Groq translation failed! Error: {e}\")\n",
        "        return transcription, \"Translation Failed\", None\n",
        "\n",
        "    # 3. Generate image (Using Hugging Face) if checkbox is ticked\n",
        "    if generate_image_checkbox:\n",
        "        try:\n",
        "            print(\"üé® Calling HF API for image generation...\")\n",
        "            image_output = inference_client.text_to_image(english_text, model=IMAGE_MODEL_ID)\n",
        "            print(\"‚úÖ Image generated successfully!\")\n",
        "        except Exception as e:\n",
        "            gr.Warning(f\"Image generation failed! The model might be loading. Error: {e}\")\n",
        "\n",
        "    return transcription, english_text, image_output\n",
        "\n",
        "# --- Function for Tab 2: Prompt to Image (Using Hugging Face) ---\n",
        "def generate_image_from_prompt(prompt):\n",
        "    if not prompt or not prompt.strip():\n",
        "        gr.Warning(\"Prompt is empty. Please enter some text.\")\n",
        "        return None\n",
        "    try:\n",
        "        print(f\"üé® Calling HF API for image generation from prompt: '{prompt}'\")\n",
        "        image = inference_client.text_to_image(prompt, model=IMAGE_MODEL_ID)\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        gr.Error(f\"Image generation failed! The model might be loading. Please try again. Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Function for Tab 3: Groq Chatbot ---\n",
        "async def chatbot_response(message, history):\n",
        "    print(\"üí¨ Generating chatbot response with Groq...\")\n",
        "    history_groq_format = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
        "    for human, assistant in history:\n",
        "        history_groq_format.append({\"role\": \"user\", \"content\": human})\n",
        "        history_groq_format.append({\"role\": \"assistant\", \"content\": assistant})\n",
        "    history_groq_format.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    try:\n",
        "        chat_completion = await groq_async_client.chat.completions.create(\n",
        "            messages=history_groq_format,\n",
        "            model=\"moonshotai/kimi-k2-instruct\"\n",
        "        )\n",
        "        return chat_completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        gr.Error(f\"Chatbot failed! Error: {e}\")\n",
        "        return f\"Sorry, I encountered an error: {e}\"\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# PART 5: BUILD THE GRADIO USER INTERFACE\n",
        "# ==============================================================================\n",
        "print(\"üöÄ Building the Gradio interface...\")\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ü§ñ All-in-One AI Suite (Groq Audio + HF Images)\")\n",
        "    gr.Markdown(\"**Tab 1**: Audio transcription & translation powered by Groq | **Tab 2**: Image generation by Hugging Face | **Tab 3**: Chatbot by Groq\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # --- Tab 1: Audio Processing (Groq) ---\n",
        "        with gr.TabItem(\"üéôÔ∏è Audio to Text & Image\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    audio_input = gr.Audio(type=\"filepath\", label=\"Upload Audio File\")\n",
        "                    language_dropdown = gr.Dropdown(\n",
        "                        choices=[\"Auto-detect\", \"Tamil\", \"English\"],\n",
        "                        value=\"Auto-detect\",\n",
        "                        label=\"Source Language\"\n",
        "                    )\n",
        "                    audio_image_checkbox = gr.Checkbox(label=\"Generate Image from Translation?\", value=True)\n",
        "                    audio_button = gr.Button(\"Process Audio\", variant=\"primary\")\n",
        "                with gr.Column(scale=2):\n",
        "                    transcription_output = gr.Textbox(label=\"Transcription (Original Language)\", interactive=False, lines=3)\n",
        "                    translation_output = gr.Textbox(label=\"English Text\", interactive=False, lines=3)\n",
        "                    audio_image_output = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "        # --- Tab 2: Prompt to Image (Hugging Face) ---\n",
        "        with gr.TabItem(\"üñºÔ∏è Prompt to Image\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=2):\n",
        "                    image_prompt_input = gr.Textbox(label=\"Enter your prompt\", lines=4, placeholder=\"e.g., A majestic lion in the savanna at sunset...\")\n",
        "                    image_button = gr.Button(\"Generate Image\", variant=\"primary\")\n",
        "                with gr.Column(scale=1):\n",
        "                    image_output = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "        # --- Tab 3: Chatbot (Groq) ---\n",
        "        with gr.TabItem(\"üí¨ Groq Chatbot\"):\n",
        "            gr.ChatInterface(\n",
        "                chatbot_response,\n",
        "                title=\"AI Chatbot\",\n",
        "                description=\"Ask me anything! Powered by Groq and Llama 3.\",\n",
        "                examples=[[\"Hello!\"], [\"What is the capital of India?\"], [\"Explain quantum computing in simple terms\"]],\n",
        "            )\n",
        "\n",
        "    # --- Define button click actions ---\n",
        "    audio_button.click(\n",
        "        fn=process_audio_and_generate,\n",
        "        inputs=[audio_input, language_dropdown, audio_image_checkbox],\n",
        "        outputs=[transcription_output, translation_output, audio_image_output],\n",
        "        #type=\"messages\"  # ‚úÖ Add this line\n",
        "    )\n",
        "\n",
        "    image_button.click(\n",
        "        fn=generate_image_from_prompt,\n",
        "        inputs=image_prompt_input,\n",
        "        outputs=image_output\n",
        "    )\n",
        "\n",
        "# ==============================================================================\n",
        "# PART 6: LAUNCH THE APPLICATION\n",
        "# ==============================================================================\n",
        "print(\"üéâ Launching the application! Click the public URL to open.\")\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "EUt2W4ujGZHf",
        "outputId": "30251c45-0d27-43d2-def9-41b332921bc0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Installing required libraries...\n",
            "‚úÖ Libraries installed.\n",
            "üîë Setting up API keys and authentication...\n",
            "‚úÖ Groq API Key loaded.\n",
            "‚úÖ Hugging Face Token loaded and authenticated.\n",
            "‚òÅÔ∏è Initializing API clients...\n",
            "‚úÖ Groq clients initialized (async and sync).\n",
            "‚úÖ Hugging Face Inference client initialized.\n",
            "üöÄ Building the Gradio interface...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéâ Launching the application! Click the public URL to open.\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://06d61591268078069d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://06d61591268078069d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí¨ Generating chatbot response with Groq...\n",
            "üí¨ Generating chatbot response with Groq...\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://06d61591268078069d.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}