{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "39fvTbKjW_c_",
        "outputId": "d8aa9d53-b184-4ef4-dbcf-5e4f6a830610",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Installing required libraries...\n",
            "‚úÖ Libraries installed.\n",
            "üîë Setting up API keys and authentication...\n",
            "‚úÖ Groq API Key loaded.\n",
            "‚úÖ Hugging Face Token loaded and authenticated.\n",
            "‚òÅÔ∏è Initializing API clients...\n",
            "‚úÖ Groq client initialized.\n",
            "‚úÖ Hugging Face Inference client initialized.\n",
            "üöÄ Building the Gradio interface...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéâ Launching the application! Click the public URL to open.\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://4dda698355e9c707bd.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4dda698355e9c707bd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# PART 1: INSTALL REQUIRED LIBRARIES\n",
        "# ==============================================================================\n",
        "print(\"‚è≥ Installing required libraries...\")\n",
        "!pip install gradio groq huggingface_hub -q\n",
        "print(\"‚úÖ Libraries installed.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# PART 2: IMPORTS, API KEY SETUP, AND AUTHENTICATION\n",
        "# ==============================================================================\n",
        "import gradio as gr\n",
        "import os\n",
        "from groq import Groq\n",
        "from huggingface_hub import InferenceClient, HfFolder\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"üîë Setting up API keys and authentication...\")\n",
        "\n",
        "# Securely get the Groq API key\n",
        "try:\n",
        "    GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "    os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "    print(\"‚úÖ Groq API Key loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not load Groq API Key. Please add it to Colab Secrets. Error: {e}\")\n",
        "\n",
        "# Securely get the Hugging Face token and authenticate\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HUGGING_FACE_API_KEY')\n",
        "    HfFolder.save_token(HF_TOKEN)\n",
        "    print(\"‚úÖ Hugging Face Token loaded and authenticated.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not load Hugging Face Token. Please add it to Colab Secrets. Error: {e}\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# PART 3: INITIALIZE API CLIENTS (This connects to cloud services)\n",
        "# ==============================================================================\n",
        "print(\"‚òÅÔ∏è Initializing API clients...\")\n",
        "\n",
        "# 1. Groq Client (for Chatbot Tab)\n",
        "try:\n",
        "    groq_client = Groq()\n",
        "    print(\"‚úÖ Groq client initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"üî• Error initializing Groq client: {e}\")\n",
        "\n",
        "# 2. Hugging Face Inference Client (for everything else)\n",
        "# This client will call the models running on Hugging Face's servers.\n",
        "try:\n",
        "    inference_client = InferenceClient(token=HF_TOKEN)\n",
        "    print(\"‚úÖ Hugging Face Inference client initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"üî• Error initializing Hugging Face client: {e}\")\n",
        "\n",
        "# Define the models we will call on Hugging Face's servers\n",
        "IMAGE_MODEL_ID = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "TRANSLATION_MODEL_ID = \"facebook/nllb-200-distilled-600M\"\n",
        "TRANSCRIPTION_MODEL_ID = \"openai/whisper-base\"\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# PART 4: DEFINE CORE FUNCTIONS (Using API calls)\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Function for Tab 1: Audio Processing ---\n",
        "def process_audio_and_generate(audio_path, generate_image_checkbox):\n",
        "    if not audio_path:\n",
        "        gr.Warning(\"No audio file provided. Please upload an audio file.\")\n",
        "        return \"\", \"\", None\n",
        "\n",
        "    transcription, english_text, image_output = \"\", \"\", None\n",
        "\n",
        "    # 1. Transcribe audio to text via API call\n",
        "    try:\n",
        "        print(\"üé§ Calling HF API for transcription...\")\n",
        "        transcription_result = inference_client.automatic_speech_recognition(\n",
        "            audio=audio_path,\n",
        "            model=TRANSCRIPTION_MODEL_ID\n",
        "        )\n",
        "        transcription = transcription_result['text']\n",
        "    except Exception as e:\n",
        "        gr.Error(f\"Transcription failed! The model might be loading. Please try again. Error: {e}\")\n",
        "        return \"Transcription Failed\", \"\", None\n",
        "\n",
        "    # 2. Translate text to English via API call\n",
        "    try:\n",
        "        print(\"üåê Calling HF API for translation...\")\n",
        "        translation_result = inference_client.translation(\n",
        "            text=transcription,\n",
        "            src_lang=\"tam_Taml\",\n",
        "            tgt_lang=\"eng_Latn\",\n",
        "            model=TRANSLATION_MODEL_ID\n",
        "        )\n",
        "        english_text = translation_result[0]['translation_text']\n",
        "    except Exception as e:\n",
        "        gr.Error(f\"Translation failed! Error: {e}\")\n",
        "        return transcription, \"Translation Failed\", None\n",
        "\n",
        "    # 3. Generate image via API call if checkbox is ticked\n",
        "    if generate_image_checkbox:\n",
        "        try:\n",
        "            print(\"üé® Calling HF API for image generation...\")\n",
        "            image_output = inference_client.text_to_image(english_text, model=IMAGE_MODEL_ID)\n",
        "        except Exception as e:\n",
        "            gr.Warning(f\"Image generation failed! The model might be loading. Error: {e}\")\n",
        "\n",
        "    return transcription, english_text, image_output\n",
        "\n",
        "# --- Function for Tab 2: Prompt to Image ---\n",
        "def generate_image_from_prompt(prompt):\n",
        "    if not prompt or not prompt.strip():\n",
        "        gr.Warning(\"Prompt is empty. Please enter some text.\")\n",
        "        return None\n",
        "    try:\n",
        "        print(f\"üé® Calling HF API for image generation from prompt: '{prompt}'\")\n",
        "        image = inference_client.text_to_image(prompt, model=IMAGE_MODEL_ID)\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        gr.Error(f\"Image generation failed! The model might be loading. Please try again. Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Function for Tab 3: Groq Chatbot ---\n",
        "def chatbot_response(message, history):\n",
        "    print(\"üí¨ Generating chatbot response with Groq...\")\n",
        "    history_groq_format = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
        "    for human, assistant in history:\n",
        "        history_groq_format.append({\"role\": \"user\", \"content\": human})\n",
        "        history_groq_format.append({\"role\": \"assistant\", \"content\": assistant})\n",
        "    history_groq_format.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    try:\n",
        "        chat_completion = groq_client.chat.completions.create(\n",
        "            messages=history_groq_format,\n",
        "            model=\"moonshotai/kimi-k2-instruct\"\n",
        "        )\n",
        "        return chat_completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        gr.Error(f\"Chatbot failed! Error: {e}\")\n",
        "        return f\"Sorry, I encountered an error: {e}\"\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# PART 5: BUILD THE GRADIO USER INTERFACE\n",
        "# ==============================================================================\n",
        "print(\"üöÄ Building the Gradio interface...\")\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ü§ñ All-in-One AI Suite (Cloud API Version)\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # --- Tab 1: Audio Processing ---\n",
        "        with gr.TabItem(\"üéôÔ∏è Audio to Text & Image\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    audio_input = gr.Audio(type=\"filepath\", label=\"Upload Tamil Audio (‡Æ™‡Øá‡Æö‡Øç‡Æö‡ØÅ)\")\n",
        "                    audio_image_checkbox = gr.Checkbox(label=\"Generate Image from Translation?\")\n",
        "                    audio_button = gr.Button(\"Process Audio\", variant=\"primary\")\n",
        "                with gr.Column(scale=2):\n",
        "                    transcription_output = gr.Textbox(label=\"Transcription (Tamil)\", interactive=False)\n",
        "                    translation_output = gr.Textbox(label=\"Translation (English)\", interactive=False)\n",
        "                    audio_image_output = gr.Image(label=\"Generated Image (‡Æ™‡Æü‡ÆÆ‡Øç)\")\n",
        "\n",
        "        # --- Tab 2: Prompt to Image ---\n",
        "        with gr.TabItem(\"üñºÔ∏è Prompt to Image\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=2):\n",
        "                    image_prompt_input = gr.Textbox(label=\"Enter your prompt\", lines=4, placeholder=\"e.g., A majestic lion in the savanna at sunset...\")\n",
        "                    image_button = gr.Button(\"Generate Image\", variant=\"primary\")\n",
        "                with gr.Column(scale=1):\n",
        "                    image_output = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "        # --- Tab 3: Chatbot ---\n",
        "        with gr.TabItem(\"üí¨ Groq Chatbot\"):\n",
        "            gr.ChatInterface(\n",
        "                chatbot_response,\n",
        "                title=\"AI Chatbot\",\n",
        "                description=\"Ask me anything! Powered by Groq and Llama 3.\",\n",
        "                examples=[[\"Hello!\"], [\"What is the capital of India?\"]]\n",
        "            )\n",
        "\n",
        "    # --- Define button click actions ---\n",
        "    audio_button.click(\n",
        "        fn=process_audio_and_generate,\n",
        "        inputs=[audio_input, audio_image_checkbox],\n",
        "        outputs=[transcription_output, translation_output, audio_image_output]\n",
        "    )\n",
        "\n",
        "    image_button.click(\n",
        "        fn=generate_image_from_prompt,\n",
        "        inputs=image_prompt_input,\n",
        "        outputs=image_output\n",
        "    )\n",
        "\n",
        "# ==============================================================================\n",
        "# PART 6: LAUNCH THE APPLICATION\n",
        "# ==============================================================================\n",
        "print(\"üéâ Launching the application! Click the public URL to open.\")\n",
        "demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}